\chapter{Stand der Technik und Wissenschaft}
\label{chap:stand-der-technik}

LiDAR hat sich in modernen Fahrerassistenzsystemen (ADAS) und beim automatisierten Fahren als zentrale Sensortechnologie etabliert. Im Vergleich zu Kameras (empfindlich gegenüber Beleuchtung/Blendung) und Radar (robust, jedoch begrenzte Winkelauflösung) liefert LiDAR hochgenaue Distanzinformationen mit hoher Winkelauflösung als dreidimensionale Punktwolken. Historisch stammt LiDAR aus Geodäsie, Fernerkundung und Atmosphärenforschung und fand mit Fortschritten in Laser- und Optoelektronik seit den 2000er‑Jahren zunehmend Eingang in die Automobiltechnik. Ziel dieses Kapitels ist die Darstellung der wissenschaftlich‑technischen Grundlagen, relevanter Messprinzipien und Anwendungen sowie der in dieser Arbeit verwendeten Sensorik.

\section{Sensoraufbau}
\label{sec:sensoraufbau}
Ein LiDAR-Sensor umfasst Sendeoptik und Strahlablenkung, Empfangsoptik und Lichtsensor sowie Auslese- und Steuerungselektronik.

\subsection{Sendeoptik und Strahlablenkung}
Die Sendeoptik formt das Intensitätsprofil und beeinflusst damit Reichweite, Divergenz und Winkelauflösung. Refraktive Linsen oder diffraktive optische Elemente (DOE) erzeugen die gewünschte Strahlform. Rasternde Systeme nutzen Spiegel/Prismen (rotierend/oszillierend) zur Ablenkung und sukzessiven Abtastung; Flash‑Systeme beleuchten die Szene pro Aufnahme vollständig (z.\,B. mit Diffusoren/DOE). Die Strahlablenkung ist das zentrale Element zur Erzeugung der Winkelinformation über den erfassten Raumwinkel.

\subsection{Empfangsoptik und Lichtsensor}
Die Empfangsoptik sammelt das rückgestreute Licht; Apertur und Transmission bestimmen das Signal gemäß der LiDAR‑Gleichung. Antireflexbeschichtungen und auf die Quelle abgestimmte Durchlässigkeit reduzieren Rauschen durch Umgebungslicht. Als Detektoren kommen typischerweise Avalanche‑Photodioden (APD) oder SPAD‑Arrays zum Einsatz; sie bieten hohe Empfindlichkeit und kurze Anstiegszeiten für schwache, kurze Pulse.

\subsection{Auslese- und Steuerungselektronik}
Verstärker, ADC/TDC und Multiplexer digitalisieren die Signale und bestimmen die Laufzeit je Messpunkt. Moderne Sensoren berechnen Distanzwerte auf Sensorebene und übernehmen Vorverarbeitung (z.\,B. Mehrfach‑Echo, Intensität). Die Steuerung selektiert aktive Zeitfenster (Reduktion von Umgebungslicht), synchronisiert Ablenkung und Detektion und ordnet Messpunkte den Raumwinkeln zu.

\section{Wellenlängenbereiche und Augensicherheit}
\label{sec:wellenlaenge}
Automotive LiDAR arbeitet überwiegend im nahen Infrarot (NIR): \(\sim\)\SIrange{870}{950}{\nano\meter} (Si‑Detektoren) sowie \SI{1064}{\nano\meter} oder \SI{1550}{\nano\meter} (InGaAs‑Detektoren). 905\,nm‑Systeme sind kosteneffizient, profitieren von verfügbarer Halbleitertechnologie und ausreichender Detektorempfindlichkeit; 1550\,nm erlaubt innerhalb der IEC~60825‑1‑Grenzen höhere Sendeleistungen (geringere Netzhautgefährdung), erfordert jedoch teurere Detektoren und ggf. aufwändigere Optik. Atmosphärische Fenster, solare Spektralanteile und Streuung an Partikeln (Mie‑Streuung) beeinflussen Reichweite und Robustheit bei Regen/Nebel \parencite{Amann2001LaserRanging}.

\section{Messprinzipien}
\label{sec:messprinzip}
\subsection{Direct Time‑of‑Flight (dToF)}
Beim dToF wird ein kurzer Laserpuls ausgesendet, am Objekt reflektiert und mit Lichtgeschwindigkeit \(c\) detektiert. Aus der gemessenen Zeitdifferenz \(\Delta t\) zwischen Emission und Detektion ergibt sich die Entfernung \(d\):
\begin{equation}
  d = \frac{c \cdot \Delta t}{2}
\end{equation}
Der Faktor \(\tfrac{1}{2}\) berücksichtigt Hin‑ und Rückweg \parencite{Amann2001LaserRanging}.

\subsection{Indirect ToF (iToF)}
iToF bestimmt Distanzen über die Phasenverschiebung einer modulierten Dauerlichtquelle. Vorteile sind kompakte, teils kostengünstige Sensorik und gute Kurzstreckenpräzision; Grenzen liegen in Ambiguität (Mehrdeutigkeit) und erhöhter Multipath‑Empfindlichkeit \parencite{Amann2001LaserRanging}.

\subsection{FMCW‑LiDAR}
Frequenzmoduliertes Dauerstrich‑LiDAR (FMCW) misst Entfernung und Relativgeschwindigkeit (Doppler) über Frequenzchirps. Vorteile sind Interferenzresistenz und gleichzeitige Geschwindigkeitsmessung; demgegenüber stehen höhere Auswerte‑ und Hardwarekomplexität \parencite{Behroozpour2017LidarArch}.

\subsection{Fehlerquellen}
Wesentliche Fehlerquellen sind Zeitjitter (TDC/ADC), Multipath, Einfallswinkelabhängigkeit, Strahldivergenz, Oberflächenreflektivität, Temperatur‑/Drifteinflüsse sowie mechanischer Jitter (Drehzahl). Sie beeinflussen Reichweite, Präzision und die Zuverlässigkeit der Segmentierung/Klassifikation.

\section{Typische Anwendungsszenarien im Fahrzeugumfeld}
\label{sec:anwendung}
LiDAR unterstützt zentrale ADAS‑Funktionen (AEB, ACC, LKA), Freiraum‑/Belegtheitsdetektion, Hinderniserkennung sowie hochautomatisierte Fahrfunktionen (3D‑Umfeldmodellierung, SLAM, Lokalisierung, Baustellen‑/Engstellenmanagement). In der Sensorsuite ergänzt LiDAR Kamera und Radar durch präzise 3D‑Geometrie. Limitationen entstehen bei Nebel/Regen, geringer Oberflächenreflektivität und Interferenzen; robuste Fusion und fehlertolerante Algorithmen sind daher notwendig. Leistungsanforderungen umfassen definierte Bildraten, End‑zu‑Ende‑Latenzen und Robustheitsmetriken \parencite{Arnold2019Survey}.

\section{Algorithmischer Stand der Technik}
Für LiDAR‑Umfelderkennung werden typischerweise folgende Bausteine kombiniert:
\begin{itemize}
  \item \textbf{Vorverarbeitung:} Downsampling (z.\,B. \emph{VoxelGrid}), Ausreißerfilter (\emph{Statistical/Radius Outlier Removal}), ggf. Bewegungsentzerrung, Intensitätsnormalisierung, Polarkoordinaten/BEV‑Darstellung, Mehrfach‑Echo‑Nutzung.
  \item \textbf{Bodensegmentierung:} RANSAC‑Ebene \parencite{FischlerBolles1981}, Progressive Morphological Filter (PMF) \parencite{Zhang2003PMF}, gitterbasierte Höhenkarten, Cloth Simulation Filtering (CSF) \parencite{Zhang2016CSF}, probabilistische Modelle (z.\,B. Gaussian Processes); robust gegenüber Neigungen/Bordsteinen.
  \item \textbf{Clustering:} Euklidische Clusterung, DBSCAN/HDBSCAN \parencite{Ester1996DBSCAN}, Region Growing; Parameter (Epsilon/Radius, Mindestpunkte) steuern Auflösung und Rauschtoleranz.
  \item \textbf{Detektion/Klassifikation:} Geometrische Merkmale (PCA, OBB, Formfeatures) oder lernbasierte 3D‑Detektoren (z.\,B. Pillars/SECOND/CenterPoint), BEV‑Pipelines; Kompromiss zwischen Datenbedarf, Robustheit und Laufzeit.
  \item \textbf{Tracking:} KF/EKF/UKF, JPDAF/MHT sowie praxisnahe Multi‑Target‑Pipelines (Datenassoziation per NN/IoU, Geburt/Tod‑Logik, Bewegungsmodelle).
\end{itemize}

\section{Ouster OS1 am Opel Astra der TH Nürnberg}
\subsection{Spezifische Eigenschaften des Ouster OS1}
Der OS1 ist ein 360\textdegree{}‑LiDAR mittlerer Reichweite. Er arbeitet bei \(\approx\)\SI{865}{\nano\meter} mit \(360\textdegree{}\) horizontalem und \(\approx\)\SI{42.4}{\degree} vertikalem Sichtfeld. Je nach Konfiguration sind 32/64/128 Vertikalkanäle verfügbar; horizontal \(512/1024/2048\) Messpunkte pro Umdrehung. Je nach Modus entstehen \(\sim\)\(1.3\)–\(5.2\)\,M Punkte/s. Typische Reichweiten liegen bis \(\sim\)\SI{170}{\meter} (hohe Reflektivität) bzw. \(\sim\)\SI{90}{\meter} (dunkle Oberflächen, starke Sonne). Distanzgenauigkeit \(\approx\)\(\pm\)\SI{2.5}{\centi\meter}, typische Präzision \(\pm\)\SIrange{0.5}{3}{\centi\meter}. Bis zu zwei Echos pro Puls werden registriert. Datenfelder umfassen Distanz, Intensität/Reflexivität, Kanalnummer, Azimut und Zeitstempel; zusätzlich liefert eine IMU Bewegungsdaten mit \SI{100}{\hertz}. Die Ausgabe erfolgt über Gigabit‑Ethernet (UDP), das Gehäuse ist nach IP68/IP69K geschützt; Betriebstemperatur von \(-\)\SI{40}{\celsius} bis \(+\)\SI{60}{\celsius} \parencite{OusterOS1}.

\subsection{Sensorpositionierung am Opel Astra}
Für die Fahrzeugintegration sind Montageort (Dachmitte), Aufbauhöhe und Neigung so zu wählen, dass das vertikale Sichtfeld den Nahbereich abdeckt und Fahrzeugteile nicht occludieren. Die Extrinsik wird relativ zu \texttt{base\_link} bestimmt (z.\,B. Zieltafel/ICP) und über \textit{tf2} bereitgestellt; relevante Frames sind \texttt{map}, \texttt{odom}, \texttt{base\_link}, \texttt{os\_sensor}/\texttt{os\_lidar}. Die Zeitbasis wird vorzugsweise per PTP synchronisiert. Messunsicherheiten (Kalibrierung, Synchronisation) wirken direkt auf Segmentierung, Detektion und Tracking und sind in der Bewertung zu berücksichtigen.

\section{Bezug zu den Forschungsfragen}
Die Auswahl und Ausgestaltung der Algorithmen richtet sich an den Anforderungen der Kapitel zur Vorverarbeitung, Cluster‑/Bounding‑Box‑Bildung und Objektverfolgung aus. Bewertet werden Genauigkeit, Robustheit und Echtzeitfähigkeit (End‑zu‑Ende‑Latenz, Ressourcenbedarf) in repräsentativen Szenarien mit OS1‑Daten. Die hier beschriebenen Eigenschaften des Sensors und der Messprinzipien begründen die methodischen Entscheidungen in den folgenden Kapiteln.
