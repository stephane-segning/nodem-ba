% ====== 1 Einleitung ======
\chapter{Einleitung}

\section{Hinführung}

Autonome und hochautomatisierte Fahrfunktionen sind auf eine präzise, robuste und nachvollziehbare Umfelderfassung angewiesen, um sicherheitskritische Entscheidungen treffen zu können. Während Kameras vor allem für semantische Informationen genutzt werden und Radar Distanz sowie Relativgeschwindigkeit zuverlässig erfasst, liefert \ac{LiDAR} dichte, dreidimensionale Punktwolken mit hoher Winkelauflösung und weitgehend konstanter Leistungsfähigkeit bei unterschiedlichen Lichtverhältnissen \parencite{Arnold2019Survey}. Dadurch bildet \ac{LiDAR} in modernen Sensorarchitekturen einen zentralen Baustein der Umfeldwahrnehmung.

Im Projekt \textit{CarCeptionX} wird ein speziell ausgestattetes Versuchsfahrzeug eingesetzt, um die Leistungsfähigkeit automobiler Umfeldsensorik systematisch zu analysieren und neue Einsatzpotenziale zu erschließen (\cite{IFZN_Projekte}). Das Ziel des Projekts ist es, auf Basis realer Messdaten sowohl die sensorische Leistungsgrenzen als auch mögliche Optimierungspotenziale zu identifizieren, um langfristig einen Beitrag zu einer sicheren, effizienten und nachhaltigen Mobilität zu leisten. Der verwendete Versuchsträger (Opel Astra) ist hierfür mit einem umfassenden Sensorsetup ausgestattet, bestehend aus:

\begin{itemize}
    \item Ouster \ac{OS1} 360°-\ac{LiDAR},
    \item Valeo Scala~2 \ac{LiDAR},
    \item Bosch General Purpose Radar,
    \item Valeo Fisheye-Kamera,
    \item Valeo Ultraschallsensor-Kit (12~Sensoren).
\end{itemize}

Am Institut für Fahrzeugtechnik Nürnberg (IFZN) wurde die \ac{LiDAR}-basierte Umfelderfassung bereits in mehreren Arbeiten untersucht. Einen wesentlichen Grundstein legte die Masterarbeit von Wendel~(2025), in der eine Sensorplattform auf dem Opel Astra aufgebaut und eine erste \ac{ROS}\,2-basierte Messkette zur Erfassung und Visualisierung von Punktwolken entwickelt wurde \parencite{Wendel2025}. Diese bestehende Infrastruktur – bestehend aus Datenerfassung, \ac{ROS}\,2-Publish/Subscribe-Architektur, MATLAB-Anbindung über eine GUI sowie Visualisierung in \textit{RViz2} – bildet das Fundament der vorliegenden Arbeit.

Die anschließende Arbeit von Sagdic~(2025) erweiterte diese Grundlage um die vollständige Anbindung und initiale Inbetriebnahme des Ouster~\ac{OS1} auf dem Versuchsträger und dokumentierte die grundlegenden Funktions- und Schnittstellenprüfungen \parencite{Sagdic2025}. Auf dieser Basis setzt die vorliegende Arbeit auf, indem sie die bisher vorhandene Messkette um ein vollständiges, echtzeitfähige Verarbeitungssystem ergänzt. 

Im Mittelpunkt steht dabei nicht der Sensor selbst, sondern die systematische Entwicklung, Implementierung und Bewertung der einzelnen Verarbeitungsschritte, die notwendig sind, um aus den Rohpunktwolken des Ouster~\ac{OS1} eine robuste Objekterkennung abzuleiten. Hierzu gehören die Vorverarbeitung der Punktwolken, eine zuverlässige Bodensegmentierung, die Clusterbildung zur Objektabgrenzung sowie die anschließende zeitliche Verfolgung der detektierten Objekte. Ziel ist es, die gesamte Verarbeitungskette so auszugestalten, dass sie unter realen urbanen Messbedingungen zuverlässig funktioniert und im Rahmen zukünftiger Forschungsaktivitäten wie \textit{CarCeptionX} nahtlos einsetzbar ist.

Zur Umsetzung dieser modularen und reproduzierbaren Verarbeitung wird das Robot Operating System~2 (\ac{ROS}~2) eingesetzt, das mit standardisierten Nachrichtenformaten, deterministischen Kommunikationsmechanismen und integrierten Visualisierungstools ein etabliertes Softwareframework für mobile Robotersysteme darstellt \parencite{Macenski2022ROS2,ROS2Docs}. Die vorliegende Arbeit erweitert die bestehende Messkette des \ac{OS1} um zusätzlich implementierte Filter-, Segmentierungs- und Trackingmodule, welche die Punktwolke schrittweise in semantisch verwertbare Objektlisten überführen und damit einen funktionsfähigen Beitrag zur Weiterentwicklung des Versuchsträgers leisten.

\section{Themenspezifizierung und Abgrenzung}

Ziel dieser Arbeit ist die Entwicklung und Evaluierung einer modularen, echtzeitfähigen Verarbeitungskette zur \ac{LiDAR}-basierten Umfelderkennung auf Basis des hochauflösenden Ouster~\ac{OS1}. Unter realen Bedingungen soll diese Verarbeitungskette spezifische Verkehrsteilnehmer ab einer Größe von~$\geq 0{,}5\,\text{m}$ mit einer Detektionsrate von mindestens $90\,\%$ bei einer minimalen Ausführungsrate von $10\,\text{Hz}$ erkennen.

 Im Mittelpunkt stehen dabei mehrere klar abgegrenzte Arbeitsschritte: die qualitätssteigernde Vorverarbeitung der Rohpunktwolken zur Reduktion von Rauschen und Ausreißern sowie zur effizienten Datenreduktion, eine verlässliche und szenariounabhängige Bodensegmentierung, die eine stabile Trennung zwischen befahrbarer Fläche und Hindernissen ermöglicht, die extraktionssichere Bildung von Clustern und konsistenten Bounding-Boxen zur Objektabgrenzung sowie die anschließende zeitliche Verfolgung der erkannten Objekte. Die Implementierung erfolgt vollständig in \ac{ROS}~2 mit dem Anspruch, eindeutig definierte Schnittstellen, reproduzierbare Experimente und messbare Leistungskennzahlen hinsichtlich Latenz, Frequenz und Genauigkeit zu gewährleisten.

Nicht Bestandteil der Arbeit sind Themenfelder, die zusätzliche Sensorquellen, umfangreiche Trainingsdaten oder andere Zielsetzungen erfordern. Dazu zählen insbesondere Sensorfusion mit Radar- oder Kamerasystemen, tiefenlernbasierte semantische Segmentierung, hardwareseitige Sensorauslegung sowie herstellerübergreifende Performancevergleiche. Ebenfalls ausgeschlossen wird das Gebiet des \textit{Simultaneous Localization and Mapping} (\ac{SLAM}). \ac{SLAM} umfasst die gleichzeitige Schätzung der Fahrzeugpose und den Aufbau einer konsistenten Umgebungskarte. Obwohl \ac{LiDAR} hierfür ein zentrales Sensormedium darstellt, verfolgt diese Arbeit weder den Aufbau globaler Karten noch die Minimierung von Lokalisierungsfehlern. Der Fokus liegt ausschließlich auf der lokalen Umfeldwahrnehmung zur Objekterkennung, die ohne globale Konsistenzbedingungen oder kartengestützte Optimierung auskommt; die Kalibrierung beschränkt sich daher auf die notwendige Extrinsik und Zeitsynchronisation.

\section{Beitrag der Arbeit, Vorgehen und Aufbau}

Die Arbeit liefert einen wissenschaftlich und technisch fundierten Beitrag zur \ac{LiDAR}-basierten Umfelderfassung, indem eine modular aufgebaute und echtzeitfähige \ac{ROS}~2-Verarbeitungsstrecke entwickelt, implementiert und systematisch untersucht wird. Der Schwerpunkt liegt auf (i) einer qualitätssteigernden Vorverarbeitung, (ii) einer präzisen Trennung von Boden- und Objektpunkten, (iii) einer verlässlichen Cluster- und Bounding-Box-Ermittlung sowie (iv) einer konsistenten Objektverfolgung. Ein weiterer Beitrag besteht in der strukturierten Gegenüberstellung verschiedener Boden- und Clusterverfahren anhand nachvollziehbarer Metriken wie Punktzahlreduktion, Stabilität der Segmentierung, Clustertrennschärfe und zeitlichem Aufwand. Sämtliche Experimente werden reproduzierbar dokumentiert und mit klar definierten Parametern durchgeführt.

Die methodische Herangehensweise integriert diese Beiträge unmittelbar in den Aufbau der Arbeit. Sie beginnt mit einer systematischen Literaturauswertung und Ableitung funktionaler Anforderungen. Darauf folgt die gezielte Datenerhebung mit dem Ouster~\ac{OS1} sowie die Implementierung der einzelnen Funktionsbausteine der Verarbeitungsstrecke. Anschließend werden diese Bausteine in \ac{ROS}~2 integriert und hinsichtlich Ausführungsmodell, Datendurchsatz und \ac{QoS}-Profilen abgestimmt. In der experimentellen Phase werden die Verfahren unter definierten Szenarien untersucht, wobei insbesondere Segmentierungsgenauigkeit, räumliche Trennschärfe, Punktverluste, Stabilität der Objektverfolgung sowie der zeitliche Aufwand pro Verarbeitungsschritt analysiert werden. Dieser integrierte Ansatz ermöglicht eine durchgängige Bewertung der im Rahmen der Arbeit entwickelten Komponenten.

Abbildung~\ref{fig:methodik} zeigt die erweiterte methodische Vorgehensweise, in der die inhaltlichen Beiträge der Arbeit direkt verortet sind.

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=7mm, >=latex]
\node (lit) [rectangle, draw, rounded corners, align=center, inner sep=3pt]
    {Literaturrecherche \\ \& Anforderungsanalyse};
\node (data) [rectangle, draw, rounded corners, below=of lit, align=center, inner sep=3pt]
    {Datenerhebung \\ mit Ouster \ac{OS1}};
\node (impl) [rectangle, draw, rounded corners, below=of data, align=center, inner sep=3pt]
    {Implementierung der \\ Verarbeitungsbausteine};
\node (integ) [rectangle, draw, rounded corners, below=of impl, align=center, inner sep=3pt]
    {Integration in \ac{ROS}\,2};
\node (eval) [rectangle, draw, rounded corners, below=of integ, align=center, inner sep=3pt]
    {Experimentelle Evaluierung \\ nach definierten Metriken};
\node (disc) [rectangle, draw, rounded corners, below=of eval, align=center, inner sep=3pt]
    {Vergleich der Verfahren \\ \& Analyse der Ergebnisse};

\draw[->] (lit) -- (data);
\draw[->] (data) -- (impl);
\draw[->] (impl) -- (integ);
\draw[->] (integ) -- (eval);
\draw[->] (eval) -- (disc);
\end{tikzpicture}
\caption{Methodische Vorgehensweise und Einbettung der Beiträge der Arbeit}
\label{fig:methodik}
\end{figure}

Zur Orientierung zeigt Abbildung~\ref{fig:aufbau} den strukturellen Aufbau der Arbeit. Kapitel~2 stellt den Stand der Technik vor. Kapitel~3 beschreibt die Systemarchitektur und die technische Einbettung der entwickelten Verarbeitungsstrecke. Kapitel~4 widmet sich der Vorverarbeitung der Punktwolken, gefolgt von der Bodensegmentierung in Kapitel~5. Kapitel~6 behandelt die Cluster-Extraktion und die Ermittlung von Bounding-Boxes. Kapitel~7 beschreibt die Objektverfolgung. Kapitel~8 umfasst die Tests und die Bewertung der Ergebnisse, bevor Kapitel~9 die Erkenntnisse zusammenfasst und einen Ausblick gibt.

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=6mm, >=latex]
\node (k2) [rectangle, draw, rounded corners, inner sep=3pt] {Kapitel 2: Stand der Technik};
\node (k3) [rectangle, draw, rounded corners, below=of k2, inner sep=3pt] {Kapitel 3: Systemarchitektur};
\node (k4) [rectangle, draw, rounded corners, below=of k3, inner sep=3pt] {Kapitel 4: Vorverarbeitung};
\node (k5) [rectangle, draw, rounded corners, below=of k4, inner sep=3pt] {Kapitel 5: Bodensegmentierung};
\node (k6) [rectangle, draw, rounded corners, below=of k5, inner sep=3pt] {Kapitel 6: Cluster \& Bounding-Boxes};
\node (k7) [rectangle, draw, rounded corners, below=of k6, inner sep=3pt] {Kapitel 7: Objektverfolgung};
\node (k8) [rectangle, draw, rounded corners, below=of k7, inner sep=3pt] {Kapitel 8: Tests \& Bewertung};
\node (k9) [rectangle, draw, rounded corners, below=of k8, inner sep=3pt] {Kapitel 9: Fazit \& Ausblick};

\draw[->] (k2) -- (k3);
\draw[->] (k3) -- (k4);
\draw[->] (k4) -- (k5);
\draw[->] (k5) -- (k6);
\draw[->] (k6) -- (k7);
\draw[->] (k7) -- (k8);
\draw[->] (k8) -- (k9);
\end{tikzpicture}
\caption{Struktur der Arbeit}
\label{fig:aufbau}
\end{figure}